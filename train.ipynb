{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from model import BatchProgramCC\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_pickle('parsed_source.pkl').sample(frac=1)\n",
    "word2vec = Word2Vec.load(\"word2vec_node_50\").wv\n",
    "\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = word2vec.syn0.shape[0]\n",
    "EMBEDDING_DIM = word2vec.syn0.shape[1]\n",
    "embeddings = np.zeros((MAX_TOKENS + 1, EMBEDDING_DIM), dtype=\"float32\")\n",
    "embeddings[:word2vec.syn0.shape[0]] = word2vec.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODE_DIM = 64\n",
    "HIDDEN_DIM = 32\n",
    "LABELS = 1\n",
    "BATCH_SIZE = 10\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BatchProgramCC(EMBEDDING_DIM,HIDDEN_DIM,MAX_TOKENS+1,ENCODE_DIM,LABELS,BATCH_SIZE,USE_GPU, embeddings)\n",
    "if USE_GPU: model.cuda()\n",
    "    \n",
    "parameters = model.parameters()\n",
    "optimizer = torch.optim.Adamax(parameters)\n",
    "loss_function = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    total_loss = 0.\n",
    "    permutation = torch.randperm(len(train_data))\n",
    "    for i in range(0, len(train_data), BATCH_SIZE):\n",
    "        idx = permutation[i:i+BATCH_SIZE]\n",
    "        batch_x = train_data['block_seq'].to_numpy()[idx]\n",
    "        batch_y = train_data['b_label'].to_numpy()[idx]\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model.batch_size = len(batch_y)\n",
    "        model.hidden = model.init_hidden()\n",
    "        output = model(batch_x)\n",
    "        \n",
    "        loss = loss_function(output[0], Variable(torch.FloatTensor(batch_y)))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "def evaluate(eval_model, data):\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    permutation = torch.randperm(len(data))\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data), BATCH_SIZE):\n",
    "            idx = permutation[i:i+BATCH_SIZE]\n",
    "            batch_x = data['block_seq'].to_numpy()[idx]\n",
    "            batch_y = data['b_label'].to_numpy()[idx]\n",
    "\n",
    "            model.batch_size = len(batch_y)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(batch_x)\n",
    "            loss = loss_function(output[0], Variable(torch.FloatTensor(batch_y)))\n",
    "            total_loss += loss\n",
    "            \n",
    "            y_pred.extend(output[0].reshape(-1,))\n",
    "            y_true.extend(batch_y.reshape(-1,))\n",
    "        \n",
    "    return total_loss, y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| end of epoch   1 | time: 11.06s | train loss  7.07| valid loss  1.21\n",
      "| end of epoch   2 | time: 11.50s | train loss  6.56| valid loss  1.19\n",
      "| end of epoch   3 | time: 10.68s | train loss  6.46| valid loss  0.83\n",
      "| end of epoch   4 | time: 14.11s | train loss  6.36| valid loss  0.82\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 20\n",
    "best_model = None\n",
    "best_epoch = -1\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss = train()\n",
    "    val_loss,_,_ = evaluate(model,val_data)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | train loss {:5.2f}| valid loss {:5.2f}'.format(epoch, (time.time() - epoch_start_time),train_loss, val_loss))\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "        best_epoch = epoch\n",
    "\n",
    "print(\"best_epoch\",best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle('parsed_source_test.pkl').sample(frac=1)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Testing...\")\n",
    "test_loss, y_pred, y_true = evaluate(best_model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = [x>0.5 for x in y_pred]\n",
    "print(metrics.classification_report(y_true, y_pred_class, target_names = [\"Non-Defect\", \"Defect\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUC\", metrics.roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtying: split into 3 groups: buggy/ problematic/ fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtyping(eval_model, data):\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    permutation = torch.randperm(len(data))\n",
    "    \n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data), BATCH_SIZE):\n",
    "            idx = permutation[i:i+BATCH_SIZE]\n",
    "            batch_x = data['block_seq'].to_numpy()[idx]\n",
    "            batch_y = data['b_label'].to_numpy()[idx]\n",
    "\n",
    "            model.batch_size = len(batch_y)\n",
    "            model.hidden = model.init_hidden()\n",
    "            output = model(batch_x)\n",
    "            outputs.append(output[1].data.numpy())\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = subtyping(best_model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = np.concatenate((outputs),axis=0)\n",
    "doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "k=3\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(doc)\n",
    "group_id = {i: np.where(kmeans.labels_ == i)[0] for i in range(k)}\n",
    "\n",
    "Counter(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buddy = test_data['label'].to_numpy()\n",
    "for gid in range(k):\n",
    "    print(len(group_id[gid]), np.mean(buddy[group_id[gid]].reshape(-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
